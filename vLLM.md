[How to run gpt-oss with vLLM](https://cookbook.openai.com/articles/gpt-oss/run-vllm)

[Batch inference on OpenShift AI with Ray Data, vLLM, and CodeFlare](https://developers.redhat.com/articles/2025/08/07/batch-inference-openshift-ai-ray-data-vllm-and-codeflare#)

[Ollama to vLLM a Roadmap for Scalable LLM Deployment](https://blog.gopenai.com/ollama-to-vllm-a-roadmap-for-scalable-llm-deployment-337775441743)
