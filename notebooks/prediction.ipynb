{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import authenticate\n",
    "credentials, PROJECT_ID = authenticate() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "REGION = \"us-central1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import vertexai\n",
    "from vertexai.language_models import TextGenerationModel\n",
    "\n",
    "vertexai.init(project = PROJECT_ID,\n",
    "              location = REGION,\n",
    "              credentials = credentials)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading a pre trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TextGenerationModel.from_pretrained(\"text-bison@001\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_tuned_models = model.list_tuned_model_names()\n",
    "\n",
    "for i in list_tuned_models:\n",
    "    print (i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Randomly select from one of the endpoints to divide the prediction load, here endpoint means the rest API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "tuned_model_select = random.choice(list_tuned_models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting a response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deployed_model = TextGenerationModel.get_tuned_model\\\n",
    "(tuned_model_select)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT = \"How can I load a csv file using Pandas?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### depending on the latency of your prompt\n",
    "### it can take some time to load\n",
    "response = deployed_model.predict(PROMPT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pprint makes the response easily readable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### load the first object of the response\n",
    "output = response._prediction_response[0]\n",
    "\n",
    "### print the first object of the response\n",
    "pprint(output)\n",
    "\n",
    "### load the second object of the response\n",
    "output = response._prediction_response[0][0]\n",
    "\n",
    "### print the second object of the response\n",
    "pprint(output)\n",
    "\n",
    "### retrieve the \"content\" key from the second object\n",
    "final_output = response._prediction_response[0][0][\"content\"]\n",
    "\n",
    "### printing \"content\" key from the second object\n",
    "print(final_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prompt management "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INSTRUCTION = \"\"\"\\\n",
    "Please answer the following Stackoverflow question on Python.\\\n",
    "Answer it like\\\n",
    "you are a developer answering Stackoverflow questions.\\\n",
    "Question:\n",
    "\"\"\"\n",
    "\n",
    "QUESTION = \"How can I store my TensorFlow checkpoint on\\\n",
    "Google Cloud Storage? Python example?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT = f\"\"\"\n",
    "{INSTRUCTION} {QUESTION}\n",
    "\"\"\"\n",
    "\n",
    "print(PROMPT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_response = deployed_model.predict(PROMPT)\n",
    "\n",
    "output = final_response._prediction_response[0][0][\"content\"]\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Safety attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### retrieve the \"blocked\" key from the \n",
    "### \"safetyAttributes\" of the response\n",
    "blocked = response._prediction_response[0][0]\\\n",
    "['safetyAttributes']['blocked']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see if any response was blocked, True is it was, else False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(blocked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### retrieve the \"safetyAttributes\" of the response\n",
    "safety_attributes = response._prediction_response[0][0]\\\n",
    "['safetyAttributes']\n",
    "\n",
    "pprint(safety_attributes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Citations if LLM is taking references from some place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### retrieve the \"citations\" key from the \n",
    "### \"citationMetadata\" of the response\n",
    "citation = response._prediction_response[0][0]\\\n",
    "['citationMetadata']['citations']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(citation)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
