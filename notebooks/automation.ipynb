{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Kubeflow Pipelines to automate, and create a ML pipeline \n",
    "\n",
    "We can also use Apache Airflow these both are orchestration tools, that can help us to design the ML workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kfp import dsl #its like a drawing board to design our workflow\n",
    "from kfp import compiler\n",
    "\n",
    "# Ignore FutureWarnings in kfp\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", \n",
    "                        category=FutureWarning, \n",
    "                        module='kfp.*')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kubeflow has 2 parts - components and pipelines\n",
    "\n",
    "Components are like self contained sets of code that perform a certain steps in our ML workflow, like data preprocessing or pre training the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building a simple workflow "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Simple example: component 1\n",
    "@dsl.component\n",
    "def say_hello(name: str) -> str:\n",
    "    hello_text = f'Hello, {name}!'\n",
    "    \n",
    "    return hello_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Simple example: component 2\n",
    "@dsl.component\n",
    "def how_are_you(hello_text: str) -> str:\n",
    "    \n",
    "    how_are_you = f\"{hello_text}. How are you?\"\n",
    "    \n",
    "    return how_are_you"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Simple example: pipeline\n",
    "@dsl.pipeline\n",
    "def hello_pipeline(recipient: str) -> str:\n",
    "    \n",
    "    # notice, just recipient and not recipient.output\n",
    "    hello_task = say_hello(name=recipient)\n",
    "    \n",
    "    # notice .output\n",
    "    how_task = how_are_you(hello_text=hello_task.output)\n",
    "    \n",
    "    # notice .output\n",
    "    return how_task.output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compiler.Compiler().compile(hello_pipeline, 'pipeline.yaml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These arguments are ingected into the pipeline during execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_arguments = {\n",
    "    \"recipient\": \"World!\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To view the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat pipeline.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import `PipelineJob` \n",
    "from google.cloud.aiplatform import PipelineJob\n",
    "\n",
    "job = PipelineJob(\n",
    "        ### path of the yaml file to execute\n",
    "        template_path=\"pipeline.yaml\",\n",
    "        ### name of the pipeline\n",
    "        display_name=f\"deep_learning_ai_pipeline\",\n",
    "        ### pipeline arguments (inputs)\n",
    "        ### {\"recipient\": \"World!\"} for this example\n",
    "        parameter_values=pipeline_arguments,\n",
    "        ### region of execution\n",
    "        location=\"us-central1\",\n",
    "        ### root is where temporary files are being \n",
    "        ### stored by the execution engine\n",
    "        pipeline_root=\"./\",\n",
    ")\n",
    "\n",
    "### submit for execution\n",
    "job.submit()\n",
    "\n",
    "### check to see the status of the job\n",
    "job.state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Real life pileline example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reuse and existing Kubeflow pipeline to fine tune a Google foundation model \"PaLM 2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### these are the same \n",
    "### jsonl files from the previous lab\n",
    "\n",
    "### time stamps have been removed so that \n",
    "### the files are consistent for all learners\n",
    "TRAINING_DATA_URI = \"./tune_data_stack_overflow_python_qa.jsonl\" \n",
    "EVAUATION_DATA_URI = \"./tune_eval_data_stack_overflow_python_qa.jsonl\"  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Versioning the model using date and time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### path to the pipeline file to reuse\n",
    "### the file is provided in your workspace as well\n",
    "template_path = 'https://us-kfp.pkg.dev/ml-pipeline/\\\n",
    "large-language-model-pipelines/tune-large-model/v2.0.0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "date = datetime.datetime.now().strftime(\"%H:%d:%m:%Y\")\n",
    "\n",
    "MODEL_NAME = f\"deep-learning-ai-model-{date}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINING_STEPS = 200\n",
    "EVALUATION_INTERVAL = 20\n",
    "\n",
    "from utils import authenticate\n",
    "credentials, PROJECT_ID = authenticate() \n",
    "\n",
    "REGION = \"us-central1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining the arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_arguments = {\n",
    "    \"model_display_name\": MODEL_NAME,\n",
    "    \"location\": REGION,\n",
    "    \"large_model_reference\": \"text-bison@001\",\n",
    "    \"project\": PROJECT_ID,\n",
    "    \"train_steps\": TRAINING_STEPS,\n",
    "    \"dataset_uri\": TRAINING_DATA_URI,\n",
    "    \"evaluation_interval\": EVALUATION_INTERVAL,\n",
    "    \"evaluation_data_uri\": EVAUATION_DATA_URI,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For using with Vertex AI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pipeline_root \"./\"\n",
    "\n",
    "job = PipelineJob(\n",
    "        ### path of the yaml file to execute\n",
    "        template_path=template_path,\n",
    "        ### name of the pipeline\n",
    "        display_name=f\"deep_learning_ai_pipeline-{date}\",\n",
    "        ### pipeline arguments (inputs)\n",
    "        parameter_values=pipeline_arguments,\n",
    "        ### region of execution\n",
    "        location=REGION,\n",
    "        ### root is where temporary files are being \n",
    "        ### stored by the execution engine\n",
    "        pipeline_root=pipeline_root,\n",
    "        ### enable_caching=True will save the outputs \n",
    "        ### of components for re-use, and will only re-run those\n",
    "        ### components for which the code or data has changed.\n",
    "        enable_caching=True,\n",
    ")\n",
    "\n",
    "### submit for execution\n",
    "job.submit()\n",
    "\n",
    "### check to see the status of the job\n",
    "job.state"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
